import numpy as np
import cupy as cp
import pandas as pd
import cudf
import pickle
import plotly.graph_objects as go
import plotly.io as pio
import matplotlib.pyplot as plt

from tifffile import imread, imwrite, TiffFile

from myutils import save_tiff_from_tensor, gen_guided_cropped_tiff, gen_random_cropped_tiff, gen_pkl_of_guided_cropped_tiff
from myclustering import reduce_pca, kmeans_clustering_gpu
from dinov2plugin import zero_shot_inference, zero_shot_inference_v2, zero_shot_inference_v3, zero_shot_visualization, zero_shot_visualization_v2, fine_tuned_inference, trained_inference, trained_inference_v3

############## METHODS FOR TEST MODE ONLY ################
# pick-up 1st line of the list for testing
def get_first_line_of_txt(txt_file):
    with open(txt_file, "r") as f:
        for line in f.readlines():
            return line[:-3]

def get_samples_from_raw_data_test_mode(txt_file):
    f = get_first_line_of_txt(txt_file)
    print("The sample " + f + " will be used for test...")

    return f

def plot_coords(file_path):
    df = pd.read_csv(file_path, usecols=['X_centroid','Y_centroid'])
    x = df['X_centroid']
    y = df['Y_centroid']
    fig, ax = plt.subplots()
    ax.scatter(x, y)
    plt.show()
##########################################################
def get_tiff_info(raw_file, img_info_file):
    print("START!")
    print("Reading " + raw_file)
    with TiffFile(raw_file) as tif:
        t_shape, t_dtype, t_axes = tif.series[0].shape, tif.series[0].dtype, tif.series[0].axes
        imageDescription = tif.pages[0].tags['ImageDescription'].value
    print("The shape, dtype and axes of the raw images are:")
    print(t_shape)
    print(t_dtype)
    print(t_axes)
    print("Saving image description information...")
    with open(img_info_file, 'w') as f:
        f.write(imageDescription)
    print("The image information file is saved to " + img_info_file + "...")

def get_samples_from_raw_data(raw_file, path, name, to_file, num_samples, channels, window_size):
    print("Loading " + raw_file)
    gen_random_cropped_tiff(raw_file, channels, num_samples, 1, 0, window_size, window_size, "auto-track", path+name, to_file)
    print("The samples are saved to " + path + ", and the list is saved to " + to_file + "...")

def get_registration_results():
# nothing to do with the implementation
    print("Start to register images to DAPI...")

def get_segmentation_results(seg_input_file, method, to_file, channels, num_inputs):
    print("Start to segment images...")
    if method == "random":
        print("The segmentation information is generated by random crop")

    print("The segmentation results are saved to " + to_file + "...")

def get_inputs_for_feature_extraction(sample_path, seg_info_path, path, name, to_file, num_inputs, channels, window_size):
    print("Start to crop the image according to " + seg_info_path + "...")
    #gen_guided_cropped_tiff(sample_path, seg_info_path, channels, num_inputs, window_size, window_size, path+name, to_file)
    gen_pkl_of_guided_cropped_tiff(sample_path, seg_info_path, channels, num_inputs, window_size, window_size, path+name, to_file)
    print("The inputs are saved to " + path + ", and the list is saved to " + to_file + "...")
    ## take a look at the coordinates
    #print("Start printing coordinates")
    #plot_coords(seg_info_path)

def get_features_extracted(inputs_path, to_file, transform, model, dev):
    ########
    # DINO #
    ########
# zeroshot
    #features = zero_shot_inference(model, dev, inputs_path, transform)
    #features = zero_shot_inference_v3(model, dev, inputs_path, transform)
    #features_df = pd.DataFrame(features)
    #features_df.to_pickle(to_file)
    #print(features_df)
# zeroshot visuallization
    #print("The features are saved to " + to_file + "...")
    #zero_shot_visualization(model, dev, inputs_path, transform)
    #zero_shot_visualization_v2(model, dev, inputs_path, transform)
# fine tuning to be a classifier
    #fine_tune_labels_list_file = "/archive/bioinformatics/Jamieson_lab/shared/spatial-core/ky/mini_pipeline/fine_tune/fine_tune_labels.txt"
    #to_file = "/archive/bioinformatics/Jamieson_lab/shared/spatial-core/ky/mini_pipeline/fine_tune/fine_tuned_dinov2_vits14.pth"
    #fine_tuned_inference(model, dev, inputs_path, transform, fine_tune_labels_list_file, to_file)
# training to be a feature extractor
    to_file = "/archive/bioinformatics/Jamieson_lab/shared/spatial-core/ky/mini_pipeline/train/trained_dinov2_vits14.pth"
    #trained_inference(model, dev, inputs_path, transform, to_file)
    trained_inference_v3(model, dev, inputs_path, transform, to_file)

def get_clustering_labels(features_file, dim_reduction_method, clustering_method, to_file):
# the features are not necessarily being saved as a DF(?)
    df = pd.read_pickle(features_file)
    features = cudf.DataFrame.from_pandas(df).to_cupy()
# dim reduction
    if dim_reduction_method == 0:
        tmp = reduce_pca(features, 20)
    else:
        print("Not using dimention reduction method!")
        tmp = features
# clustering
    if clustering_method == 0:
        labels = kmeans_clustering_gpu(tmp, 5, 42)
    else:
        print("Not using KMeans clustering method!")
        labels = []
# save to file
    with open(to_file, 'wb') as f:
        pickle.dump(labels, f)
    print("The labels are saved to " + to_file + "...")

def get_labels_visualized(labels_file, segmentation_file, num_points, to_file):
    labels = pd.read_pickle(labels_file)
    df1 = pd.read_csv(segmentation_file, usecols=['X_centroid','Y_centroid'], nrows=num_points)
    df2 = pd.DataFrame(labels[:num_points], columns=['markers'])
    fig = go.Figure(go.Scatter(x=df1['X_centroid'], y=df1['Y_centroid'], mode='markers', marker=dict(color=df2['markers'], colorscale='Viridis', showscale=True)))
    pio.write_image(fig, to_file, width=1080, height=1080, scale=2)
    print("The clustering image is saved to " + to_file + "...")
    print("DONE!")
